RDF represents data as triples forming a directed, labeled graph and each subject–predicate–object triple encodes a statement.
To convert the HECATE CSV catalog into RDF based on the Parsec ontology, we employ the RDF Mapping Language (RML).
RML allows us to declaratively specify how each row of the CSV maps to RDF as each Triples Map corresponds to an 
entity or concept in the data.
The Subject Map within a TriplesMap defines how to construct the subject URI for each row.
R2RML/RML requires exactly one subject map per TriplesMap.
The Predicate-Object Maps (POMs) generate the rest of the triples for each subject. 
Each POM pairs one predicate with one or more object maps.
When a POM’s object is generated by another TriplesMap, we use a referencing object map with rr:parentTriplesMap. 
This says “the object is the subject of the given parent TriplesMap” and since all data comes from the same CSV row we
do not need explicit Join conditions the engine does the work for us.

About the Uri Construction:
For measurements and identifiers, we used both the galaxy {PGC} value and the column name. This ensures each measurement URI encodes its parent galaxy and attribute. 
example: https://hecate.ia.forth.gr/celestial_body/{galaxyID}/column/{columnName}/measurement/{id}
Several data transformations were done before mapping. Columns were added to the CSV so that every piece of information required for the mapping had its own field.
For example some columns included error margins(see RA and newly added E_RA) so in the preprocessing file the computation was made and a new column was added in the csv.
Another example a column added as D_Estimation_Method to record codes like “N” or “Z” for NED-D vs regression methods.
These preprocessing steps allowed our RML mapping to simply do straight lookups (with rml:reference) without needing complex in-map expressions.

On edge cases: 
Rml naturally doesn't display a triplet which has an empty value.
So it automatically skips a predicateObjectMap because the value is an empty string
 (like R = ""), but it still generates the subject and other triples, like:
rdf:type parsec:E8_Measurement
P21_is_measurement_from_column ColumnR
As we found out this is a core limitation of how RML Mapper works and this happens because those triples don’t depend on R itself, but they’re being generated due to the subjectMap:
rr:subjectMap [
    rr:template "https://.../galaxy_{PGC}_R"
    rr:class parsec:E8_Measurement
];
even if R is missing, a subject URI is created, and the class/type triple gets emitted.
RML Mapper does not support conditional logic at the subject level so even rr:condition and fnml:functionMap or fno works only for predicateObjectMaps, not subjects.



Some things to notice/ errors encountered 
In our the original mapping, each <#MeasurementXXX> block had its own declaration of the source:
rml:logicalSource [
    rml:source "hekate_10_galaxies_with_errors.csv" ;
    rml:referenceFormulation ql:CSV ;
] ;
The problem is that RML does not guarantee per-row isolation unless you configure join conditions explicitly so something like 
rr:template "https://hecate.ia.forth.gr/measurement/DEC/{PGC}" ; does not restrict the predicateObjectMap to its "own" row only.
So, due to that, RML ended up linking measurements across rows incorrectly
eg. galaxy 2 mistakenly linking to galaxy 3's DEC measurement, because DEC/3 matched a row where PGC was 3, but got attached during the processing for PGC=2.
This is a side effect of row-based context not being cleanly scoped, especially when referencing columns from multiple mappings without isolating them.
The issue was fixed by:
Replacing the inline rml:logicalSource [...] blocks with a single shared source URI like this:
<#HekateCSV> a rml:LogicalSource ;
    rml:source "hekate_10_galaxies_with_errors.csv" ;
    rml:referenceFormulation ql:CSV .
and then using:
rml:logicalSource <#HekateCSV> ;
so now all mappings read from the same input record stream. The RML row context is consistently scoped by the engine.


Another thing of notice is that in executing a small batch of the csv (1000 lines) there was no notable difference in the execution time when the output file is changed.
Tested file types of rdf, ttl and nt as seen in screenshot with not much of a notable change.


Extra things added(not needed in the scope of the project)
In order to automate a change needed in the uri of all the mappings done in the original parsec file we created a java file with the name MeasurementUriRewriter.java
that finds and replaces the links from the wrong one https://parsec.forth.gr/measurement/{PGC} to the correct new one 
https://parsec.forth.gr/celestial_body/galaxy_{PGC}/column/measurement/galaxy_{PGC}_

Another java file by the name  was created to automate the column and measurement mappings. It is a simple program that asks for a column name
as user input as well as an error margin column or reliability status one and then output a basic mapping in the file specified.
It was used in our final mappings for some columns which will have an - Autogenerated tag. This can be further expanded to match more use cases as needed

